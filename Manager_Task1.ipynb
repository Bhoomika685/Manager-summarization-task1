{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOArTvJks5FFN8/8BHM6j5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhoomika685/Manager-summarization-task1/blob/main/Manager_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Step 1: Install dependencies\n",
        "# ============================\n",
        "!pip install transformers --quiet\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load summarizer model\n",
        "summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\")\n",
        "\n",
        "# ============================\n",
        "# Step 2: Define Conversation Manager\n",
        "# ============================\n",
        "class ConversationManager:\n",
        "    def __init__(self, trunc_limit_turns=None, trunc_limit_words=None, k_periodic=3):\n",
        "        self.history = []  # full conversation history\n",
        "        self.k_periodic = k_periodic  # summarize after every k turns\n",
        "        self.trunc_limit_turns = trunc_limit_turns\n",
        "        self.trunc_limit_words = trunc_limit_words\n",
        "        self.summaries = []  # store summaries\n",
        "\n",
        "    def add_message(self, speaker, message):\n",
        "        \"\"\"Add user/assistant message and check truncation + summarization.\"\"\"\n",
        "        self.history.append(f\"{speaker}: {message}\")\n",
        "        self.apply_truncation()\n",
        "        if len(self.history) % self.k_periodic == 0:\n",
        "            self.perform_summarization()\n",
        "\n",
        "    def apply_truncation(self):\n",
        "        \"\"\"Apply truncation by turns or word length.\"\"\"\n",
        "        # Limit by turns\n",
        "        if self.trunc_limit_turns is not None:\n",
        "            self.history = self.history[-self.trunc_limit_turns:]\n",
        "        # Limit by word count\n",
        "        if self.trunc_limit_words is not None:\n",
        "            words = \" \".join(self.history).split()\n",
        "            if len(words) > self.trunc_limit_words:\n",
        "                words = words[-self.trunc_limit_words:]\n",
        "                self.history = [\" \".join(words)]\n",
        "\n",
        "    def perform_summarization(self):\n",
        "        \"\"\"Summarize conversation so far and replace history with summary.\"\"\"\n",
        "        text = \" \".join(self.history)\n",
        "        summary = summarizer(text, max_length=60, min_length=10, do_sample=False)[0]['summary_text']\n",
        "        self.summaries.append(summary)\n",
        "        self.history = [f\"Summary so far: {summary}\"]\n",
        "\n",
        "    def show_history(self):\n",
        "        \"\"\"Print conversation history.\"\"\"\n",
        "        print(\"\\n--- Conversation History ---\")\n",
        "        for msg in self.history:\n",
        "            print(msg)\n",
        "\n",
        "    def show_summaries(self):\n",
        "        \"\"\"Print stored summaries.\"\"\"\n",
        "        print(\"\\n--- Stored Summaries ---\")\n",
        "        for i, s in enumerate(self.summaries, 1):\n",
        "            print(f\"Summary {i}: {s}\")\n",
        "\n",
        "\n",
        "# ============================\n",
        "# Step 3: DEMO\n",
        "# ============================\n",
        "manager = ConversationManager(trunc_limit_turns=5, trunc_limit_words=50, k_periodic=3)\n",
        "\n",
        "# Simulate conversation\n",
        "manager.add_message(\"User\", \"Hello, I need help with Python loops.\")\n",
        "manager.add_message(\"Assistant\", \"Sure, I can explain Python loops like for and while.\")\n",
        "manager.add_message(\"User\", \"Great! Can you also show me examples with code?\")\n",
        "manager.show_history()\n",
        "\n",
        "# Next 3 turns\n",
        "manager.add_message(\"Assistant\", \"Of course, hereâ€™s a simple for loop that prints numbers 1 to 5.\")\n",
        "manager.add_message(\"User\", \"Thanks, what about while loop?\")\n",
        "manager.add_message(\"Assistant\", \"A while loop runs until a condition becomes false.\")\n",
        "manager.show_history()\n",
        "\n",
        "# Check summaries\n",
        "manager.show_summaries()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBI8EulrZMJt",
        "outputId": "7eda6231-a11e-4663-9d05-6d959473bdc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 60, but your input_length is only 43. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Your max_length is set to 60, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conversation History ---\n",
            "Summary so far: Assistant: Sure, I can explain Python loops like for and while .\n",
            "\n",
            "--- Conversation History ---\n",
            "Summary so far: Assistant: I can explain Python loops like for and while loops .\n",
            "Assistant: A while loop runs until a condition becomes false.\n",
            "\n",
            "--- Stored Summaries ---\n",
            "Summary 1: Assistant: Sure, I can explain Python loops like for and while .\n",
            "Summary 2: Assistant: I can explain Python loops like for and while loops .\n"
          ]
        }
      ]
    }
  ]
}